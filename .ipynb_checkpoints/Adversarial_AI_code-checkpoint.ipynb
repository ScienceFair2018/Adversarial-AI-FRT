{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b984303b",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ScienceFair2018/Adveserial-AI-FRT/blob/main/Adversarial_AI_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cd02f6-3d3a-4dbb-80f8-47540e93df99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4cd02f6-3d3a-4dbb-80f8-47540e93df99",
    "outputId": "98b9a9d2-943a-4ca5-b642-099656de98f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from torch) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: requests in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from facenet-pytorch) (2.32.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from facenet-pytorch) (9.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from facenet-pytorch) (0.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from facenet-pytorch) (1.21.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from requests->facenet-pytorch) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from requests->facenet-pytorch) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from requests->facenet-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from requests->facenet-pytorch) (1.26.16)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from torchvision->facenet-pytorch) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\baroq\\anaconda3\\envs\\deepfri\\lib\\site-packages (from torchvision->facenet-pytorch) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n",
      "WARNING: Ignoring invalid distribution -tkinter-pymol (c:\\users\\baroq\\anaconda3\\envs\\deepfri\\dlls)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c193b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e57de09-7c96-4fd7-8bb4-747332d039c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 997
    },
    "id": "0e57de09-7c96-4fd7-8bb4-747332d039c2",
    "outputId": "76930e1e-9804-435d-b0bc-ddbf9ac04d07"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InceptionResnetV1' object has no attribute 'block4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_47760\\2159763324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# Select target layer for Grad-CAM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mtarget_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DeepFRI\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1268\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m-> 1270\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'InceptionResnetV1' object has no attribute 'block4'"
     ]
    }
   ],
   "source": [
    "#### Gradcam: compare to faces\n",
    "\n",
    "def initialize_mtcnn():\n",
    "    mtcnn = MTCNN(image_size=160, margin=20, min_face_size=40)\n",
    "    return mtcnn\n",
    "\n",
    "def initialize_facenet():\n",
    "    model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "    return model\n",
    "\n",
    "def process_image(image_path, mtcnn):\n",
    "    image = Image.open(image_path)\n",
    "    face = mtcnn(image)\n",
    "    if face is None:\n",
    "        raise ValueError(\"No face detected! Try again!\")\n",
    "    return face\n",
    "\n",
    "def embeddings(model, face_tensor):\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor)\n",
    "    return embedding.squeeze().numpy()\n",
    "\n",
    "def compare_images(embedding1, embedding2):\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "def generate_gradcam(model, face_tensor, target_layer):\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    hook_backward = target_layer.register_full_backward_hook(backward_hook)\n",
    "    hook_forward = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    # Detach and enable gradients safely\n",
    "    face_tensor = face_tensor.detach().unsqueeze(0).requires_grad_(True)\n",
    "\n",
    "    output = model(face_tensor)\n",
    "    target_neuron = output.mean()\n",
    "    target_neuron.backward()\n",
    "\n",
    "    activations = activations[0].detach()\n",
    "    gradients = gradients[0].detach()\n",
    "\n",
    "    weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "    gradcam = torch.sum(weights * activations, dim=1).squeeze()\n",
    "    gradcam = torch.relu(gradcam)\n",
    "\n",
    "    gradcam = gradcam - gradcam.min()\n",
    "    gradcam = gradcam / gradcam.max()\n",
    "\n",
    "    hook_backward.remove()\n",
    "    hook_forward.remove()\n",
    "\n",
    "    return gradcam\n",
    "\n",
    "def plot_gradcam_on_face(original_image, gradcam, face_tensor):\n",
    "    gradcam_np = gradcam.numpy()\n",
    "\n",
    "    # Resize Grad-CAM heatmap to match original image dimensions\n",
    "    gradcam_resized = np.array(\n",
    "        Image.fromarray(gradcam_np).resize(original_image.size, resample=Image.BILINEAR)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(original_image)\n",
    "    plt.imshow(gradcam_resized, cmap='jet', alpha=0.6)  # Overlay heatmap\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grad-CAM Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "def highlight_important_areas(gradcam, threshold=0.01):\n",
    "    # Identify and mask areas with importance above the threshold\n",
    "    important_mask = gradcam > threshold\n",
    "    return important_mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image1 = \"biden1.jpg\"\n",
    "    image2 = \"biden2.jpg\"\n",
    "\n",
    "    mtcnn = initialize_mtcnn()\n",
    "    model = initialize_facenet()\n",
    "\n",
    "    # Select target layer for Grad-CAM\n",
    "    target_layer = model.repeat_2\n",
    "\n",
    "    try:\n",
    "        # Process images\n",
    "        face1 = process_image(image1, mtcnn)\n",
    "        face2 = process_image(image2, mtcnn)\n",
    "\n",
    "        # Generate Grad-CAM heatmaps\n",
    "        gradcam1 = generate_gradcam(model, face1, target_layer)\n",
    "        gradcam2 = generate_gradcam(model, face2, target_layer)\n",
    "\n",
    "        # Plot Grad-CAM heatmaps on the original images\n",
    "        original_image1 = Image.open(image1)\n",
    "        original_image2 = Image.open(image2)\n",
    "\n",
    "        plot_gradcam_on_face(original_image1, gradcam1, face1)\n",
    "        plot_gradcam_on_face(original_image2, gradcam2, face2)\n",
    "\n",
    "        # Compute embeddings and similarity\n",
    "        embedding1 = embeddings(model, face1)\n",
    "        embedding2 = embeddings(model, face2)\n",
    "\n",
    "        similarity = compare_images(embedding1, embedding2)\n",
    "        print(f\"Cosine Similarity between the two faces: {similarity:.4f}\")\n",
    "\n",
    "        # Highlight areas most important for identification\n",
    "        important_mask1 = highlight_important_areas(gradcam1)\n",
    "        important_mask2 = highlight_important_areas(gradcam2)\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb01ee-1463-4f1c-9cde-92a424d70f8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8beb01ee-1463-4f1c-9cde-92a424d70f8d",
    "outputId": "25429fc1-fd4b-4c9d-ab44-5f10767b7be4"
   },
   "outputs": [],
   "source": [
    "############ FGSM ########################\n",
    "epsilon = 0.1\n",
    "\n",
    "\n",
    "\n",
    "def initialize_mtcnn():\n",
    "    mtcnn = MTCNN(image_size=160, margin=20, min_face_size =40)\n",
    "    return mtcnn\n",
    "\n",
    "def initialize_facenet():\n",
    "    model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "    return model\n",
    "\n",
    "def process_image(image_path, mtcnn):\n",
    "    image = Image.open(image_path)\n",
    "    face = mtcnn(image)\n",
    "    if face is None:\n",
    "        raise ValueError(\"No face detected! Try again!\")\n",
    "    return face\n",
    "\n",
    "def embeddings(model, face_tensor):\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor)\n",
    "    return embedding.squeeze().numpy()\n",
    "\n",
    "def compare_images(embedding1, embedding2):\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "def gradcam(model, face_tensor, target_layer):\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    hook_backward = target_layer.register_backward_hook(backward_hook)\n",
    "    hook_forward = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "    face_tensor.requires_grad = True\n",
    "    output = model(face_tensor)\n",
    "\n",
    "    target_neuron = output.mean()\n",
    "    target_neuron.backward()\n",
    "\n",
    "    activations = activations[0].detach()\n",
    "    gradients = gradients[0].detach()\n",
    "\n",
    "    weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "    gradcam = torch.sum(weights * activations, dim=1).squeeze()\n",
    "    gradcam = torch.relu(gradcam)\n",
    "\n",
    "    gradcam = gradcam - gradcam.min()\n",
    "    gradcam = gradcam / gradcam.max()\n",
    "\n",
    "    hook_backward.remove()\n",
    "    hook_forward.remove()\n",
    "\n",
    "    return gradcam\n",
    "\n",
    "def plot_gradcam(image_path, gradcam, face_tensor):\n",
    "    gradcam_np = gradcam.numpy()\n",
    "\n",
    "    # Resize the Grad-CAM to match the original image dimensions\n",
    "    original_image = Image.open(image_path)\n",
    "    gradcam_resized = np.array(Image.fromarray(gradcam_np).resize(original_image.size, resample=Image.BILINEAR))\n",
    "\n",
    "    # Overlay the heatmap on the original image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(original_image)\n",
    "    plt.imshow(gradcam_resized, cmap='jet', alpha=0.6)  # Adjust alpha for better focus\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grad-Cam Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "def fgsm_attack_with_gradcam(image, epsilon, data_grad, gradcam):\n",
    "\n",
    "    gradcam = gradcam / gradcam.max()\n",
    "    gradcam = torch.tensor(gradcam, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "\n",
    "    # Resize Grad-CAM to match gradient tensor dimensions\n",
    "    gradcam_resized = F.interpolate(gradcam, size=data_grad.shape[1:], mode='bilinear', align_corners=False)\n",
    "\n",
    "    # Focus gradients using Grad-CAM\n",
    "    focused_grad = data_grad * gradcam_resized.squeeze(0)  # Remove batch dimension after resizing\n",
    "\n",
    "    # Create adversarial perturbation\n",
    "    perturbed_image = image + epsilon * focused_grad.sign()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)  # Keep pixel values valid\n",
    "    return perturbed_image\n",
    "\n",
    "\n",
    "def generate_targeted_adversarial_image(model, face_tensor, gradcam, epsilon):\n",
    "    face_tensor.requires_grad = True\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(face_tensor.unsqueeze(0))\n",
    "    target_neuron = output.mean()  # Use mean as a proxy target (e.g., similarity score)\n",
    "\n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    target_neuron.backward()\n",
    "\n",
    "    # Get gradients of the input image\n",
    "    data_grad = face_tensor.grad.data\n",
    "\n",
    "    # Generate adversarial image with focused perturbations\n",
    "    perturbed_image = fgsm_attack_with_gradcam(face_tensor, epsilon, data_grad, gradcam)\n",
    "    return perturbed_image\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image2 = \"joe_biden.jpeg\"\n",
    "\n",
    "    mtcnn = initialize_mtcnn()\n",
    "    model = initialize_facenet()\n",
    "\n",
    "    target_layer = model.block8\n",
    "\n",
    "\n",
    "    try:\n",
    "        original_image = Image.open(image2)  # Load original image\n",
    "\n",
    "        face = process_image(image2, mtcnn)\n",
    "        gradcam = gradcam(model, face, target_layer)\n",
    "        embedding1 = embeddings(model, face)\n",
    "\n",
    "        # Generate adversarial example focusing on Grad-CAM regions\n",
    "        adversarial_face2 = generate_targeted_adversarial_image(model, face, gradcam, epsilon)\n",
    "        embedding_adv2 = embeddings(model, adversarial_face2)\n",
    "\n",
    "        # Compare embeddings\n",
    "        similarity_adv = compare_images(embedding1, embedding_adv2)\n",
    "        print(f\"Cosine Similarity with adversarial perturbation (guided by Grad-CAM): {similarity_adv:.4f}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a31707-2174-41b5-aca9-e0dc87e4bea0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "23a31707-2174-41b5-aca9-e0dc87e4bea0",
    "outputId": "1f8690a8-ed79-4d22-ca6e-45d17783e0ae"
   },
   "outputs": [],
   "source": [
    "#### Gradcam: compare two faces, but with edited Biden\n",
    "\n",
    "def initialize_mtcnn():\n",
    "    mtcnn = MTCNN(image_size=160, margin=20, min_face_size=40)\n",
    "    return mtcnn\n",
    "\n",
    "def initialize_facenet():\n",
    "    model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "    return model\n",
    "\n",
    "def process_image(image_path, mtcnn):\n",
    "    image = Image.open(image_path)\n",
    "    face = mtcnn(image)\n",
    "    if face is None:\n",
    "        raise ValueError(\"No face detected! Try again!\")\n",
    "    return face\n",
    "\n",
    "def embeddings(model, face_tensor):\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor)\n",
    "    return embedding.squeeze().numpy()\n",
    "\n",
    "def compare_images(embedding1, embedding2):\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "def generate_gradcam(model, face_tensor, target_layer):\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    # Register hooks to capture gradients and activations\n",
    "    hook_backward = target_layer.register_backward_hook(backward_hook)\n",
    "    hook_forward = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    # Perform a forward pass\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "    face_tensor.requires_grad = True\n",
    "    output = model(face_tensor)\n",
    "\n",
    "    # Compute gradient of a representative neuron (mean of output)\n",
    "    target_neuron = output.mean()\n",
    "    target_neuron.backward()\n",
    "\n",
    "    # Extract gradients and activations\n",
    "    activations = activations[0].detach()\n",
    "    gradients = gradients[0].detach()\n",
    "\n",
    "    # Calculate Grad-CAM heatmap\n",
    "    weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "    gradcam = torch.sum(weights * activations, dim=1).squeeze()\n",
    "    gradcam = torch.relu(gradcam)\n",
    "\n",
    "    # Normalize heatmap\n",
    "    gradcam = gradcam - gradcam.min()\n",
    "    gradcam = gradcam / gradcam.max()\n",
    "\n",
    "    # Remove hooks\n",
    "    hook_backward.remove()\n",
    "    hook_forward.remove()\n",
    "\n",
    "    return gradcam\n",
    "\n",
    "def plot_gradcam_on_face(original_image, gradcam, face_tensor):\n",
    "    gradcam_np = gradcam.numpy()\n",
    "\n",
    "    # Resize Grad-CAM heatmap to match original image dimensions\n",
    "    gradcam_resized = np.array(\n",
    "        Image.fromarray(gradcam_np).resize(original_image.size, resample=Image.BILINEAR)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(original_image)\n",
    "    plt.imshow(gradcam_resized, cmap='jet', alpha=0.6)  # Overlay heatmap\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grad-CAM Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "def highlight_important_areas(gradcam, threshold=0.01):\n",
    "    # Identify and mask areas with importance above the threshold\n",
    "    important_mask = gradcam > threshold\n",
    "    return important_mask\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image1 = \"biden edited.jpg\"\n",
    "    image2 = \"biden2.jpg\"\n",
    "\n",
    "    mtcnn = initialize_mtcnn()\n",
    "    model = initialize_facenet()\n",
    "\n",
    "    # Select target layer for Grad-CAM\n",
    "    target_layer = model.block8\n",
    "\n",
    "    try:\n",
    "        # Process images\n",
    "        face1 = process_image(image1, mtcnn)\n",
    "        face2 = process_image(image2, mtcnn)\n",
    "\n",
    "        # Generate Grad-CAM heatmaps\n",
    "        gradcam1 = generate_gradcam(model, face1, target_layer)\n",
    "        gradcam2 = generate_gradcam(model, face2, target_layer)\n",
    "\n",
    "        # Plot Grad-CAM heatmaps on the original images\n",
    "        original_image1 = Image.open(image1)\n",
    "        original_image2 = Image.open(image2)\n",
    "\n",
    "        plot_gradcam_on_face(original_image1, gradcam1, face1)\n",
    "        plot_gradcam_on_face(original_image2, gradcam2, face2)\n",
    "\n",
    "        # Compute embeddings and similarity\n",
    "        embedding1 = embeddings(model, face1)\n",
    "        embedding2 = embeddings(model, face2)\n",
    "\n",
    "        similarity = compare_images(embedding1, embedding2)\n",
    "        print(f\"Cosine Similarity between the two faces: {similarity:.4f}\")\n",
    "\n",
    "        # Highlight areas most important for identification\n",
    "        important_mask1 = highlight_important_areas(gradcam1)\n",
    "        important_mask2 = highlight_important_areas(gradcam2)\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wob_zvX1uL68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "wob_zvX1uL68",
    "outputId": "775bbb32-5ac8-48a1-eb4a-c27c6b7cd33f"
   },
   "outputs": [],
   "source": [
    "######## PGD ##############\n",
    "epsilon = 0.05\n",
    "num_steps = 100  # Number of PGD steps\n",
    "\n",
    "def pgd_attack_with_gradcam(image, epsilon, num_steps, gradcam_map, model):\n",
    "    gradcam_map = gradcam_map / gradcam_map.max()  # Normalize Grad-CAM map\n",
    "    gradcam_map = gradcam_map.clone().detach().unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "\n",
    "    # Resize Grad-CAM map to match gradient dimensions\n",
    "    gradcam_resized = F.interpolate(gradcam_map, size=image.shape[1:], mode='bilinear', align_corners=False)\n",
    "\n",
    "    # Start with a clone of the image\n",
    "    perturbed_image = image.clone().detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        # Forward pass\n",
    "        output = model(perturbed_image.unsqueeze(0))\n",
    "        target_neuron = output.mean()\n",
    "\n",
    "        # Backward pass\n",
    "        model.zero_grad()\n",
    "        target_neuron.backward()\n",
    "\n",
    "        # Get current gradient\n",
    "        if perturbed_image.grad is None:\n",
    "            print(\"No gradients computed for perturbed_image!\")\n",
    "            break\n",
    "\n",
    "        data_grad = perturbed_image.grad.data\n",
    "\n",
    "        # Recompute focused_grad at this step\n",
    "        focused_grad = data_grad * gradcam_resized.squeeze(0)\n",
    "\n",
    "        # Apply perturbation\n",
    "        perturbed_image = perturbed_image + epsilon * focused_grad.sign()\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "        # Ensure gradient tracking\n",
    "        perturbed_image = perturbed_image.clone().detach().requires_grad_(True)\n",
    "\n",
    "    return perturbed_image\n",
    "\n",
    "\n",
    "def generate_targeted_pgd_adversarial_image(model, face_tensor, gradcam_map, epsilon, num_steps=10):\n",
    "    face_tensor = face_tensor.clone().detach().requires_grad_(True)\n",
    "\n",
    "    output = model(face_tensor.unsqueeze(0))\n",
    "    target_neuron = output.mean()\n",
    "\n",
    "    model.zero_grad()\n",
    "    target_neuron.backward()\n",
    "\n",
    "    if face_tensor.grad is None:\n",
    "        print(\"No gradients computed for face_tensor!\")\n",
    "        return None\n",
    "\n",
    "    return pgd_attack_with_gradcam(face_tensor, epsilon, num_steps, gradcam_map, model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image2 = \"joe_biden.jpeg\"\n",
    "\n",
    "    mtcnn = initialize_mtcnn()\n",
    "    model = initialize_facenet()\n",
    "\n",
    "    target_layer = model.block8  # Use the same target layer for Grad-CAM\n",
    "\n",
    "    try:\n",
    "        original_image = Image.open(image2)  # Load original image\n",
    "\n",
    "        # Process original image to obtain a face\n",
    "        face = process_image(image2, mtcnn)\n",
    "\n",
    "        # Compute Grad-CAM map\n",
    "        gradcam_map = gradcam(model, face, target_layer)  # Renamed variable\n",
    "\n",
    "        # Compute embeddings for original face\n",
    "        embedding1 = embeddings(model, face)\n",
    "\n",
    "        # Generate adversarial example using PGD guided by Grad-CAM regions\n",
    "        adversarial_face_pgd = generate_targeted_pgd_adversarial_image(model, face, gradcam_map, epsilon, num_steps)\n",
    "\n",
    "        if adversarial_face_pgd is not None:\n",
    "            # Compute embeddings for adversarial face\n",
    "            embedding_adv_pgd = embeddings(model, adversarial_face_pgd)\n",
    "\n",
    "            # Compare embeddings\n",
    "            similarity_adv_pgd = compare_images(embedding1, embedding_adv_pgd)\n",
    "            print(f\"Cosine Similarity with PGD adversarial perturbation (guided by Grad-CAM): {similarity_adv_pgd:.4f}\")\n",
    "\n",
    "            # Convert the adversarial image tensor to a NumPy array for visualization\n",
    "            if isinstance(adversarial_face_pgd, torch.Tensor):\n",
    "                adversarial_face_pgd = adversarial_face_pgd.squeeze().cpu().detach().numpy()\n",
    "                if adversarial_face_pgd.shape[0] == 3:\n",
    "                    adversarial_face_pgd = np.moveaxis(adversarial_face_pgd, 0, -1)  # Convert from [C, H, W] to [H, W, C]\n",
    "\n",
    "            # Display both the original and adversarial images\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "            # Show original image\n",
    "            axes[0].imshow(original_image)\n",
    "            axes[0].set_title(\"Original Image\")\n",
    "            axes[0].axis('off')  # Hide axes\n",
    "\n",
    "            # Show adversarial image\n",
    "            axes[1].imshow(adversarial_face_pgd)\n",
    "            axes[1].set_title(\"Adversarial Image (PGD)\")\n",
    "            axes[1].axis('off')  # Hide axes\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to generate adversarial image.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
